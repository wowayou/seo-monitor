import asyncio
import os
import time
import pandas as pd
from datetime import datetime
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError

try:
    from tqdm.asyncio import tqdm_asyncio
except ImportError:
    tqdm_asyncio = None

# ================= é…ç½®åŒº (æ ¹æ®ä½ çš„ç½‘ç»œæƒ…å†µè°ƒæ•´) =================

# 1. ä¸¥æ ¼åŠ è½½å¼€å…³ (True = ç­‰å¾…æ‰€æœ‰åœˆåœˆè½¬å®Œ; False = éª¨æ¶å‡ºæ¥å°±è¡Œ)
STRICT_LOAD_MODE = True  

# 2. ç½‘ç»œé‡è¯•è®¾ç½® (å¯¹æŠ—å›½å¤–æœåŠ¡å™¨ä¸ç¨³å®šçš„å…³é”®)
MAX_RETRIES = 2  # å¦‚æœå¤±è´¥ï¼Œè‡ªåŠ¨é‡è¯• 2 æ¬¡ (å…±å°è¯• 3 æ¬¡)

# 3. åŸºç¡€è®¾ç½®
EXCEL_PATH = "urls.xlsx"
OUTPUT_ROOT = r"C:\Users\xhl\Desktop\SEO_Monitor_Data"
CONCURRENT_TASKS = 2      # âš ï¸ ç½‘ç»œå·®æ—¶ï¼Œå¼ºçƒˆå»ºè®®æŠŠå¹¶å‘é™åˆ° 2 æˆ– 1ï¼Œé¿å…å¸¦å®½æŒ¤å…‘
PAGE_TIMEOUT = 90000      # âš ï¸ é’ˆå¯¹å›½å¤–æœåŠ¡å™¨ï¼Œè¶…æ—¶å»¶é•¿è‡³ 90ç§’
VIEWPORT_SIZE = {'width': 1440, 'height': 900}

# 4. é»‘åå• (åŠ å¿«é€Ÿåº¦ï¼Œé˜²æ­¢æ±¡æŸ“æ•°æ®)
BLOCK_DOMAINS = [
    "google-analytics.com", "googletagmanager.com", "hm.baidu.com", "cnzz.com",
    "facebook.net", "connect.facebook.net", "doubleclick.net", "googleadservices.com"
]

# =============================================================

async def slow_scroll_down(page):
    """æ¨¡æ‹Ÿå¹³æ»‘æ»šåŠ¨ï¼Œå¸¦ç†”æ–­æœºåˆ¶"""
    try:
        last_height = await page.evaluate("document.body.scrollHeight")
        scroll_count = 0
        max_scrolls = 30 

        while scroll_count < max_scrolls:
            await page.evaluate("window.scrollBy(0, window.innerHeight)")
            await asyncio.sleep(1.5) # ç¨å¾®å¤šç­‰ä¸€ä¸‹å›¾ç‰‡åŠ è½½
            
            new_height = await page.evaluate("document.body.scrollHeight")
            current_scroll_y = await page.evaluate("window.scrollY + window.innerHeight")
            scroll_count += 1
            
            if new_height == last_height or current_scroll_y >= new_height:
                # åˆ°åº•äº†ï¼Œå†æœ€åç­‰ä¸€ä¸‹ç¡®ä¿æ‡’åŠ è½½è§¦å‘
                await asyncio.sleep(2) 
                break
            last_height = new_height
    except Exception:
        pass # æ»šåŠ¨æŠ¥é”™ä¸åº”è¯¥æ‰“æ–­ä¸»æµç¨‹

async def capture_task(browser, row, semaphore):
    async with semaphore:
        project = row['Project']
        page_type = row['PageType']
        url = row['URL']
        
        task_result = {
            "Project": project,
            "PageType": page_type,
            "URL": url,
            "Status": "Pending",
            "LoadTime_s": 0.0,
            "RetryCount": 0,
            "ErrorMessage": ""
        }

        today_str = datetime.now().strftime("%Y-%m-%d")
        save_dir = os.path.join(OUTPUT_ROOT, today_str, project)
        filename = f"{page_type}.png"
        save_path = os.path.join(save_dir, filename)
        os.makedirs(save_dir, exist_ok=True)

        context = await browser.new_context(
            viewport=VIEWPORT_SIZE,
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            ignore_https_errors=True
        )
        page = await context.new_page()

        # è·¯ç”±æ‹¦æˆª
        for pattern in BLOCK_DOMAINS:
            await page.route(f"**/*{pattern}*", lambda route: route.abort())

        total_start = time.time()
        
        # --- é‡è¯•å¾ªç¯é€»è¾‘ ---
        for attempt in range(MAX_RETRIES + 1):
            try:
                task_result["RetryCount"] = attempt
                if attempt > 0:
                    print(f"   [ğŸ”„ ç¬¬{attempt}æ¬¡é‡è¯•] {project}-{page_type}...")

                load_start = time.time()

                # --- æ ¸å¿ƒç­–ç•¥ï¼šæ ¹æ®å¼€å…³é€‰æ‹©ç­‰å¾…æ–¹å¼ ---
                if STRICT_LOAD_MODE:
                    # ä¸¥æ ¼æ¨¡å¼ï¼šç­‰å¾…ç½‘ç»œç©ºé—² (è‡³å°‘500msæ²¡è¯·æ±‚)ï¼Œé€‚åˆç”±äºå›¾ç‰‡å¤šå¯¼è‡´çš„æ…¢
                    await page.goto(url, timeout=PAGE_TIMEOUT, wait_until="networkidle")
                else:
                    # å¿«é€Ÿæ¨¡å¼ï¼šDOMå‡ºæ¥å°±è¡Œ
                    await page.goto(url, timeout=PAGE_TIMEOUT, wait_until="domcontentloaded")
                
                load_duration = time.time() - load_start
                task_result["LoadTime_s"] = round(load_duration, 2)

                # æ»šåŠ¨åŠ è½½
                await asyncio.wait_for(slow_scroll_down(page), timeout=60)

                # å¦‚æœæ˜¯ä¸¥æ ¼æ¨¡å¼ï¼Œæ»šåŠ¨å®Œå†å¼ºåˆ¶ç­‰å¾…ä¸€ä¸‹ "load" äº‹ä»¶ï¼Œç¡®ä¿ä¸‡æ— ä¸€å¤±
                if STRICT_LOAD_MODE:
                     try:
                        # å°è¯•ç­‰å¾…æœ€ç»ˆçš„ load äº‹ä»¶ï¼Œå¦‚æœå·²ç»è§¦å‘è¿‡ä¼šç›´æ¥é€šè¿‡
                        await page.wait_for_load_state("load", timeout=5000)
                     except:
                        pass # å°±ç®—è¶…æ—¶ä¹Ÿä¸è¦ç´§ï¼Œåˆšæ‰å·²ç» networkidle äº†

                # æˆªå›¾
                await page.screenshot(path=save_path, full_page=True, timeout=30000)
                
                task_result["Status"] = "Success"
                print(f"[âœ… æˆåŠŸ] {project}-{page_type} (è€—æ—¶:{task_result['LoadTime_s']}s)")
                
                # æˆåŠŸäº†å°±è·³å‡ºå¾ªç¯ï¼Œä¸å†é‡è¯•
                break 

            except Exception as e:
                error_msg = str(e).splitlines()[0]
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œæ‰æ ‡è®°ä¸ºå¤±è´¥
                if attempt == MAX_RETRIES:
                    task_result["Status"] = "Failed"
                    task_result["ErrorMessage"] = error_msg
                    print(f"[âŒ æœ€ç»ˆå¤±è´¥] {project}-{page_type}: {error_msg}")
                    with open(os.path.join(save_dir, f"ERROR_{page_type}.txt"), "w") as f:
                        f.write(f"URL: {url}\nError: {str(e)}")
                else:
                    # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡ï¼Œæš‚åœä¸€ä¸‹å†è¯•
                    await asyncio.sleep(3) 

        await context.close()
        return task_result

async def main():
    if not os.path.exists(EXCEL_PATH):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ° {EXCEL_PATH}")
        return

    df = pd.read_excel(EXCEL_PATH).dropna(subset=['URL'])
    mode_str = "ä¸¥æ ¼æ¨¡å¼(ç­‰å¾…èµ„æºå…¨åŠ è½½)" if STRICT_LOAD_MODE else "æé€Ÿæ¨¡å¼(åªç­‰éª¨æ¶)"
    print(f"å‡†å¤‡å·¡æ£€ {len(df)} ä¸ªé¡µé¢ | æ¨¡å¼: {mode_str} | é‡è¯•æ¬¡æ•°: {MAX_RETRIES}")
    
    semaphore = asyncio.Semaphore(CONCURRENT_TASKS)
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-setuid-sandbox']
        )
        
        tasks = []
        for _, row in df.iterrows():
            tasks.append(capture_task(browser, row, semaphore))

        if tqdm_asyncio:
            results = await tqdm_asyncio.gather(*tasks, desc="ä»»åŠ¡è¿›åº¦")
        else:
            results = await asyncio.gather(*tasks)
            
        await browser.close()

    # ç”ŸæˆæŠ¥å‘Š
    today_str = datetime.now().strftime("%Y-%m-%d")
    report_df = pd.DataFrame(results)
    
    # æ•´ç†åˆ—
    cols = ["Project", "PageType", "Status", "LoadTime_s", "RetryCount", "URL", "ErrorMessage", "ScreenshotPath"]
    for col in cols:
        if col not in report_df.columns: report_df[col] = ""
    report_df = report_df[cols]
    
    report_path = os.path.join(OUTPUT_ROOT, today_str, "inspection_report.xlsx")
    try:
        report_df.to_excel(report_path, index=False)
        print(f"\nğŸ“„ æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    except:
        print(f"\nâš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å ç”¨")

if __name__ == "__main__":
    start_time = datetime.now()
    asyncio.run(main())
    print(f"æ€»è€—æ—¶: {datetime.now() - start_time}")